{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "907ec49b-956c-4e2b-990a-d1bb40ea22fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f73e2d-bb7b-4465-858c-d107c22497cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b13b739-6e9f-4353-b9df-777b5792a072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_array = np.array(data)\n",
    "x_data_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e501a8e5-bd48-4219-a4e0-4cee6dbd9f5f",
   "metadata": {},
   "source": [
    "From another tensor:\n",
    "\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden.\n",
    "\n",
    "텐서 복사하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2185214a-e7c4-4a03-9314-e94425daeb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48915f4-0828-4ed8-b0b8-f7b642e74aa7",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "초기화: 신경망을 구축할 때 가중치나 바이어스와 같은 매개변수를 특정 값으로 초기화해야 할 필요가 있습니다. torch.ones_like()는 특정 텐서와 동일한 모양의 텐서를 1로 초기화하는 데 사용될 수 있어, 모델의 파라미터를 일관되게 초기화하는 데 도움이 됩니다.\n",
    "\n",
    "크기와 타입 일치: 딥러닝에서는 종종 여러 텐서 간 연산을 수행해야 합니다. 이때, 연산을 수행하는 텐서들의 크기와 데이터 타입이 일치해야 합니다. torch.ones_like(data) 함수를 사용하면 data 텐서와 정확히 동일한 크기와 데이터 타입을 가진 새로운 텐서를 생성할 수 있어, 이러한 요구사항을 쉽게 충족시킬 수 있습니다.\n",
    "\n",
    "효율적인 메모리 관리: PyTorch는 내부적으로 메모리를 효율적으로 관리하고 재사용하기 위한 메커니즘을 가지고 있습니다. torch.ones_like(data) 함수는 필요한 메모리 할당을 최적화하며, 필요한 경우 재사용할 수 있도록 해줍니다. 이는 대규모 텐서를 다룰 때 특히 중요합니다.\n",
    "\n",
    "계산 그래프 유지: PyTorch에서는 텐서를 사용한 연산을 통해 자동 미분을 수행할 수 있습니다. torch.ones_like(data)로 생성된 텐서는 원본 데이터 data와 동일한 디바이스(CPU, GPU)에 위치하게 됩니다. 이는 계산 그래프를 유지하는 데 중요하며, 역전파 시 올바른 미분값을 계산하는 데 필요합니다.\n",
    "\n",
    "데이터 타입과 디바이스 일치: torch.ones_like()는 원본 텐서가 저장된 디바이스(CPU, GPU 등)와 데이터 타입(float, int 등)을 자동으로 상속받아 동일한 속성의 텐서를 생성합니다. 이는 코드를 간결하게 유지하면서도 오류를 최소화할 수 있도록 돕습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9834e19-4b75-4f78-8b2f-d882d58ddd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[0.9999, 0.6495],\n",
      "        [0.3171, 0.6105]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23edcf9d-e9b7-49bd-a3c2-8102a2337aa8",
   "metadata": {},
   "source": [
    "shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e85c4c2d-3c46-4e76-b3f7-9033e895d570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.0731, 0.8713, 0.0859],\n",
      "        [0.4114, 0.1511, 0.2869]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "# shape = (2, 3, 4)\n",
    "# shape = (2, 3, 4, 3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6ed5999-fa2b-4d20-830d-6ae8c41dbabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5a3be1a-e082-451b-a494-4206c7a87f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb90d92d-fe9a-4345-b145-199f35b2af33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f2b6b21-ecc1-4460-ad0c-c62703900543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0971a5-d8b0-456a-a3ed-7f9638a957cb",
   "metadata": {},
   "source": [
    "torch.cat 함수는 주로 여러 텐서를 지정된 차원을 따라 연결하는 데 사용됩니다. 이 함수는 딥러닝에서 다양한 목적으로 활용되지만, 일반적으로 torch.cat을 사용하여 딥러닝 구조의 마지막에 위치하는 flatten 레이어를 직접 구현하기보다는 다른 방법이 더 자주 사용됩니다.\n",
    "\n",
    "딥러닝 모델에서 마지막에 flatten 레이어를 구현하는 주요 목적은 다차원 텐서를 1차원 텐서로 변환하여, 완전 연결 레이어(fully connected layer) 또는 분류 레이어에 입력하기 쉽게 만드는 것입니다. 이 작업은 보통 torch.flatten 함수나 view 메소드를 사용하여 수행됩니다.\n",
    "\n",
    "torch.cat은 주로 차원을 유지하면서 텐서를 결합할 때 사용됩니다. 예를 들어, 두 개의 피처 맵(feature map)을 채널 차원(일반적으로 차원 1)을 따라 결합하거나, 서로 다른 레이어의 출력을 결합하여 더 복잡한 특성을 모델링할 때 유용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65bc0887-1f98-4aab-8e57-c95e9f796c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1: tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y2: tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "y3: tensor([[0.0100, 0.9688, 0.4292, 0.0484],\n",
      "        [0.3583, 0.0967, 0.8740, 0.9828],\n",
      "        [0.9867, 0.2111, 0.1726, 0.6629],\n",
      "        [0.2355, 0.9441, 0.5118, 0.9609]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "# ``tensor.T`` returns the transpose of a tensor \n",
    "y1 = tensor @ tensor.T   # @ 연산자는 행렬 곱셈(또는 점곱)   .T는 텐서의 전치(transpose)를 의미\n",
    "y2 = tensor.matmul(tensor.T) # 위의 코드와 동일함, 연산은 주어진 텐서의 각 행과 그 전치된 버전의 각 열 사이의 내적을 계산하여 새로운 행렬을 생성  \n",
    "y3 = torch.rand_like(y1)\n",
    "\n",
    "print(f\"y1: {y1}\")\n",
    "print(f\"y2: {y2}\")\n",
    "print(f\"y3: {y3}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe8fcb69-2910-4872-9857-fe42bb643937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1: tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "z2: tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "z3: tensor([[0.1423, 0.6240, 0.5858, 0.8516],\n",
      "        [0.2153, 0.4252, 0.5528, 0.4737],\n",
      "        [0.4351, 0.9037, 0.9813, 0.4234],\n",
      "        [0.4350, 0.0351, 0.8536, 0.3361]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor.T, out=y3)\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor # 요소별 곱셈(element-wise multiplication)을 수행, 이 연산은 각 텐서의 동일한 위치에 있는 요소끼리 곱합\n",
    "z2 = tensor.mul(tensor) # 위와 동일, 신경망에서 가중치를 적용하거나, 특정 패턴의 마스킹(masking) 작업을 수행\n",
    "z3 = torch.rand_like(tensor)\n",
    "\n",
    "print(f\"z1: {z1}\")\n",
    "print(f\"z2: {z2}\")\n",
    "print(f\"z3: {z3}\")\n",
    "\n",
    "\n",
    "torch.mul(tensor, tensor, out=z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c28d437-b082-4caa-a070-22344acebe46",
   "metadata": {},
   "source": [
    "Single-element tensors If you have a one-element tensor, for example by aggregating all values of a tensor into one value, you can convert it to a Python numerical value using item():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "512851e4-fa26-47f3-8544-040b59e54724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1440e9-0b54-4811-a15d-257cc0dd6eaf",
   "metadata": {},
   "source": [
    "값 추출: 계산 결과를 스칼라 값으로 받고 싶을 때, 예를 들어, 손실 함수의 결과가 단일 요소 텐서로 반환되었을 때, 이 값을 Python의 float나 int와 같은 스칼라 값으로 변환하여 다루고 싶을 때 사용됩니다.\n",
    "\n",
    "오류 검사: 특정 연산의 결과가 예상대로 단일 값을 반환하는지 확인하고, 해당 값을 직접적으로 다루기 위해 사용됩니다.\n",
    "\n",
    "item() 메서드는 반드시 단일 요소를 포함하는 텐서에만 사용할 수 있습니다. 만약 텐서가 둘 이상의 요소를 포함하고 있다면, item() 메서드를 호출하면 오류가 발생합니다. 따라서, 이 메서드는 주로 손실 값이나 단일 성능 지표를 추출할 때 사용됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5f52065-7117-4561-b1a5-3322765e27e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d80795e-1f27-4644-83d7-57667ec04c7c",
   "metadata": {},
   "source": [
    "In-place operations Operations that store the result into the operand are called in-place. They are denoted by a _ suffix. For example: x.copy_(y), x.t_(), will change x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d68ed08-7dd3-49e9-8f0a-d698ecc18964",
   "metadata": {},
   "source": [
    "Bridge with NumPy\n",
    "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29d8c9dd-9981-4ec3-b8e7-ed937ce2986e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2de5567f-93e4-4960-8f1f-396003cb2c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de00794f-cc9c-4e21-accf-68e62d418dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9eb6dade-7d37-4724-ad56-cd76d5d9e4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973db69-972a-4ff2-9143-0b9972864076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDE",
   "language": "python",
   "name": "sde"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
